&nbsp;&nbsp; 为了方便自己以后巩固与复习， 故出20道选择和10道编程设计题目， 后面会给出参考答案

## 1. 多选题目(20道)

1. 关于std::thread的构造和析构，哪些说法正确？    
A. std::thread对象析构前必须调用join()或detach()    
B. 对已调用detach()的线程，无法再调用join()    
C. 对一个未调用join()的std::thread对象析构会引发std::terminate    
D. join()后的线程可以通过std::move转移给其他std::thread对象    

2. 线程参数传递的陷阱可能包括哪些？    
A. 传递局部变量的指针，但线程运行时变量已被销毁    
B. 使用std::ref传递非const引用    
C. 传参时发生隐式类型转换（如const char*转std::string）    
D. 传递std::unique_ptr时未使用std::move    

3. 关于线程所有权转移，正确的是？   
A. std::thread对象只能通过std::move转移所有权    
B. std::thread t1(f); std::thread t2 = t1;是合法操作    
C. std::thread对象可作为函数返回值    
D. std::thread对象存入std::vector需要显式调用std::move    

4. 关于join()和detach()，错误的是？   
A. join()会阻塞当前线程直至目标线程结束    
B. detach()后的线程生命周期与std::thread对象无关   
C. 对已join()的线程再次调用join()会导致编译错误    
D. detach()的线程资源由C++运行时自动回收    

5. 如何正确使用RAII管理线程？    
A. thread_guard在析构时调用join()    
B. scoped_thread的构造函数必须检查线程是否可join    
C. RAII对象在异常发生时自动释放线程资源    
D. thread_guard禁止拷贝构造和赋值操作    

6. 下面代码可能的问题是什么？  
	```cpp
	void f(int& x) { x++; }
	int main() {
	    int a = 0;
	    std::thread t(f, a);
	    t.join();
	}
	
	```
	A. 参数a未使用std::ref传递    
	B. x++未加锁，导致数据竞争    
	C. 线程t的参数会拷贝到新线程栈    
	D. a的修改对主线程不可见     

7. 关于硬件并发的正确描述是？  
A. std::thread::hardware_concurrency()返回的是物理CPU核心数    
B. 硬件并发数一定等于可并行执行的最大线程数    
C. 任务切换可以实现与硬件并发相同的性能    
D. 多核系统中，硬件并发数可能大于1    

8. 以下哪些操作会抛出std::system_error？  
A. 对未关联线程的std::thread对象调用join()    
B. 对已detach()的std::thread对象调用detach()    
C. 对joinable()为false的线程调用join()    
D. 构造std::thread时参数类型不匹配    

9. 关于std::async，正确的是？    
A. 默认策略下可能在新线程或当前线程执行任务    
B. std::launch::deferred表示延迟到get()调用时执行    
C. std::async的返回值可以忽略    
D. 必须通过std::future获取结果    

10. 以下场景可能引发数据竞争的是？
A. 两个线程同时读取同一非原子变量    
B. 一个线程写，另一个线程读未同步的共享变量    
C. 使用std::mutex保护所有共享变量访问    
D. 原子变量的load()和store()无内存序约束    

11. 关于互斥量，错误的是？  
A. std::lock_guard在作用域结束时自动释放锁    
B. std::unique_lock支持手动加锁和解锁    
C. 递归互斥量允许同一线程重复加锁    
D. std::mutex的lock()和unlock()必须配对调用    

12. 条件变量的正确用法是？  
A. wait()必须在循环中检查条件    
B. notify_one()会唤醒所有等待线程    
C. std::condition_variable必须与std::mutex配合使用    
D. wait()会自动释放锁并阻塞线程    

13. 关于原子操作，正确的描述是？  
A. std::atomic<int>::load()保证顺序一致性    
B. memory_order_relaxed不提供同步保证    
C. fetch_add()是原子的读-修改-写操作    
D. 原子操作能完全取代互斥量的使用    

14. 设计无锁数据结构的关键挑战是？  
A. 正确处理ABA问题    
B. 确保所有操作均为原子    
C. 避免死锁和优先级反转    
D. 依赖硬件支持的原子指令    

15. 关于内存模型，错误的是？  
A. C++内存模型定义了多线程下的操作可见性     
B. std::atomic默认使用memory_order_seq_cst    
C. 编译器可能对非原子操作进行指令重排    
D. memory_order_consume适用于依赖数据排序    

16. 线程池的优点是？  
A. 减少线程创建销毁的开销    
B. 自动负载均衡    
C. 避免线程数量超过硬件并发数    
D. 支持优先级调度    

17. 以下哪些是多线程调试的常用工具？  
A. Valgrind Helgrind    
B. ThreadSanitizer    
C. GDB的info threads命令    
D. 基于日志的追踪    

18. 哪些情况下推荐使用并发？     
A. 需要实时响应大量用户输入    
B. 计算密集型任务可利用多核CPU    
C. 单个任务的执行时间极短    
D. IO操作频繁导致等待时间过长    

19. 以下说法错误的是？  
A. 线程切换的开销通常小于进程切换    
B. 并发一定比串行的性能更好    
C. 数据并行适用于SIMD架构    
D. 无锁数据结构一定比基于锁的高效    

20. 关于C++17并行算法，正确的是？  
A. 使用std::execution::par指定并行策略   
B. 所有标准算法均有并行版本    
C. 并行算法要求输入范围支持随机访问    
D. 可以自动避免数据竞争    

## 2. 设计题目(10道)

1. 多生产者多消费者线程安全环形队列
   要求：
   实现基于无锁设计的环形缓冲区，支持多个生产者和消费者同时操作。使用CAS保证操作的原子性，处理ABA问题。缓冲区满时生产者阻塞，空时消费者阻塞，使用C++11原子变量和条件变量。
2. 内存屏障控制的多核计数器
   要求：
   设计高性能原子计数器，支持fetch_add操作，要求严格顺序一致性。使用memory_order_seq_cst，对比改为memory_order_relaxed后的正确性差异。验证不同内存序下多线程操作的可见性。
3. Promise/Future实现异步流水线
   要求：
   构建异步处理流水线：数据读取→预处理→加密→写入文件。每阶段用独立线程处理，阶段间用promise/future传递结果。处理异常传播，确保加密失败时整个流水线优雅终止。
4. 可中断线程池实现
   要求：
   实现可响应外部中断的线程池，支持动态提交任务和立即取消未执行任务。使用std::jthread（或自定义中断点）停止运行中的任务。要求管理未完成任务队列的线程安全清理。
5. CAS无锁栈的ABA问题解决方案
   要求：
   实现无锁栈结构，解决ABA问题。采用"带标记指针"或双重CAS策略，验证插入/删除操作的线程安全性。测试高并发场景下栈的正确性，比较与有锁版本的性能差异。
6. 基于条件变量的工作窃取调度器
   要求：
   设计工作窃取(Work-Stealing)调度器：每个Worker线程维护双端队列，空闲线程窃取其他队列任务。使用std::mutex和条件变量同步任务获取，避免死锁，实现负载均衡。
7. 并行快速排序优化
   要求：
   使用C++17并行算法执行策略实现快速排序。对比std::execution::par与手动线程池实现的性能差异。处理递归划分时的任务调度，确保小数组切换为串行排序。
8. 细粒度锁的哈希表设计
   要求：
   构建线程安全哈希表，每个桶独立加锁，支持高并发插入/查找/删除。实现动态扩缩容机制，确保rehash时不阻塞全表。测试不同锁粒度（全局锁 vs 分段锁）下的吞吐量。
9. 检测并修复死锁场景
   要求：
   编写一个必然发生死锁的代码片段（例如：多个线程按不同顺序请求互斥锁）。使用分层锁策略或std::lock/std::scoped_lock修复死锁。集成Valgrind或TSAN工具验证修复效果。
10. 原子操作实现无锁内存池
    要求：
    实现基于原子操作的无锁内存池，支持多线程高效分配/释放固定大小内存块。使用链表管理空闲块，通过CAS更新头指针。验证内存分配的正确性，处理高并发下的性能瓶颈。

## 参考答案：
### 多选题
1. ABC
   详解: A正确：std::thread对象析构前必须调用join()或detach()，否则会触发std::terminate（文档2.1.3节）。B正确：调用detach()后，线程生命周期独立于对象，对已分离的线程调用join()会导致未定义行为。C正确：未调用join()或detach()直接析构std::thread对象会引发std::terminate。D错误：join()后的线程已结束，线程对象不再管理任何线程，移动所有权没有意义。
2. ACD
   详解 : A正确：传递局部变量的指针或引用，线程运行时变量可能已销毁（代码2.1的示例）。C正确：隐式转换（如const char*转std::string）可能在参数构造前完成变量销毁（文档2.2节）。D正确：传递std::unique_ptr需用std::move显式转移所有权，否则会触发拷贝构造错误（文档2.2结尾）。B陷阱值：使用std::ref传递非const引用是合法且正确的做法，但如果函数不接受引用，则不会传递引用，造成拷贝。
3. ACD
   详解: A正确：std::thread只能通过移动语义转移所有权（文档2.3节）。B错误：std::thread不可复制，std::thread t2 = t1非法（文档2.3.1节）。C正确：std::thread对象可以作为函数返回值（代码2.5示例）。D正确：将std::thread对象存入容器（如std::vector）需显式移动（代码2.8中的emplace_back）。
4. C
   详解 :A正确：join()会阻塞当前线程直至目标线程结束。B正确：detach()后的线程生命周期与对象无关。C错误：对已join()的线程再次调用join()会抛出std::system_error（运行时错误），但不会导致编译错误。D正确：detach()的线程资源由C++运行时自动回收（文档2.1.4节）。
5. ABCD
   详解： A正确：thread_guard析构时调用join()（代码2.3）。B正确：scoped_thread构造函数检查线程是否可join()（代码2.6构造函数中的检查）。C正确：RAII对象在析构时释放资源，确保异常时线程安全。D正确：thread_guard禁止拷贝构造和赋值操作（代码2.3中=delete声明）。
6. A
   详解：选项 A：在 C++ 中，当使用 std::thread 创建线程并传递参数时，如果要传递引用，必须使用 std::ref 进行包装。在给定的代码中，std::thread t(f, a); 本意是将 a 的引用传递给 f 函数，但实际上没有使用 std::ref，这样 a 会被拷贝到新线程的栈中，而不是传递引用。因此，函数 f 操作的是 a 的拷贝，而不是 a 本身，所以选项 A 正确。选项 B：虽然代码没有加锁，但由于传递的不是真正的引用，不会出现多个线程同时访问和修改同一个变量的情况，所以不存在数据竞争问题，选项 B 错误。选项 C：std::thread 构造函数在不使用 std::ref 时会拷贝参数，但这不是本题的核心问题，核心问题是没有正确传递引用，选项 C 错误。选项 D：由于没有正确传递引用，a 本身并没有被修改，也就不存在修改对主线程不可见的问题，选项 D 错误。
7. D
   详解：选项 A：std::thread::hardware_concurrency() 返回的是一个建议值，表示当前系统中可以并发执行的线程数量，这个值可能是逻辑 CPU 核心数，而不一定是物理 CPU 核心数，因为现代 CPU 可能支持超线程技术，一个物理核心可以模拟多个逻辑核心，选项 A 错误。选项 B：硬件并发数只是一个参考值，实际可并行执行的最大线程数还受到系统资源（如内存、I/O 等）的限制，所以硬件并发数不一定等于可并行执行的最大线程数，选项 B 错误。选项 C：任务切换会带来一定的开销，包括保存和恢复线程上下文等操作，而硬件并发是多个核心同时执行任务，性能通常优于任务切换，选项 C 错误。选项 D：在多核系统中，每个核心都可以独立执行任务，因此硬件并发数可能大于 1，选项 D 正确。
8. AB
  详解：选项 A：对未关联线程的 std::thread 对象调用 join() 会抛出 std::system_error，因为 join() 操作要求线程对象必须关联一个可执行的线程，选项 A 正确。选项 B：对已 detach() 的 std::thread 对象再次调用 detach() 会抛出 std::system_error，因为一个线程只能被 detach() 一次，选项 B 正确。选项 C：对 joinable() 为 false 的线程调用 join() 不会抛出异常，join() 函数内部会先检查 joinable() 的状态，如果为 false 则不会执行任何操作，选项 C 错误。选项 D：构造 std::thread 时参数类型不匹配会导致编译错误，而不是运行时抛出 std::system_error，选项 D 错误。
9. ABC
   详解：选项 A：std::async 默认的启动策略是 std::launch::async | std::launch::deferred，这意味着任务可能在新线程中执行，也可能在调用 get() 或 wait() 时在当前线程中执行，选项 A 正确。选项 B：std::launch::deferred 策略表示任务会被延迟执行，直到调用 get() 或 wait() 时才会开始执行，选项 B 正确。选项 C：std::async 的返回值可以忽略，不过这样可能会导致一些资源管理问题，因为 std::async 返回的 std::future 对象在析构时会阻塞等待任务完成，选项 C 正确。选项 D：虽然通常通过 std::future 获取 std::async 的结果，但也可以选择忽略结果，不一定必须通过 std::future 获取，选项 D 错误。
10. B
   详解：选项 A：两个线程同时读取同一非原子变量不会引发数据竞争，因为读取操作不会修改变量的值，只要没有写操作同时进行，就不会出现数据不一致的问题，选项 A 错误。选项 B：一个线程写，另一个线程读未同步的共享变量会引发数据竞争，因为写操作和读操作可能会同时进行，导致读取到的数据可能是不完整或不一致的，选项 B 正确。选项 C：使用 std::mutex 保护所有共享变量访问可以避免数据竞争，因为 std::mutex 可以确保同一时间只有一个线程能够访问共享变量，选项 C 错误。选项 D：原子变量的 load() 和 store() 操作即使没有内存序约束，也不会引发数据竞争，因为原子操作本身是线程安全的，选项 D 错误。
11. D. std::mutex的lock()和unlock()必须配对调用（错误说法）
   解析：std::mutex的lock()和unlock()必须由同一线程配对调用，否则行为未定义。而选项D的描述看似正确，但结合上下文，句意可能混淆了“线程配对”而非“次数上严格一对一”，因此选项D的设计存在问题。实际使用中，RAII类型（如std::lock_guard或std::unique_lock）更安全，但手动调用仍需配对。题目选项设定可能存在争议。

12. A. wait()必须在循环中检查条件（正确）
   解析：为避免虚假唤醒，条件变量的wait()必须在循环中检查条件。其他选项中，B错误（notify_one仅唤醒一个线程），C正确（需配合std::mutex），D正确（wait()自动释放锁）。

13. ABC（均为正确描述）
   解析：A正确（std::atomic<int>::load()默认顺序一致性）。B正确（memory_order_relaxed无同步保证）。
   C正确（fetch_add()是原子读-改-写操作）。
   D错误（原子操作不能完全替代互斥量）。
14. A. 正确处理ABA问题（正确）
   解析：无锁数据结构需解决ABA问题（如指针重复使用导致误判），其他选项中B（确保所有操作原子）、C（避免死锁）、D（硬件指令依赖）非核心关键。

15. D. memory_order_consume适用于依赖数据排序（正确描述，但题目可能存在误导）
   解析：理论上选项D正确，但实践中多数编译器未完全支持memory_order_consume，常用acquire替代。题目可能意在考察实际应用，可能预期D为错误选项，但结合标准描述，题目存在矛盾。若必须选择，D仍为正确选项，题目可能存在瑕疵。
16. AC
   线程池通过复用线程减少开销（A正确），并限制线程数以匹配硬件并发（C正确）。自动负载均衡（B）和优先级调度（D）依赖于具体实现。
17. ABCD
   这些工具分别用于检测竞争条件（A、B）、查看线程状态（C）和分析执行流程（D）。
18. ABD
   并发可分离界面与后台任务（A）、加速计算（B）、利用IO等待时间（D）。短任务易受切换开销影响（C不推荐）。
19. BD
   并发可能因同步开销降低性能（B错误）；无锁结构在高争用时可能更慢（D错误）。
20. A
    并行算法需手动避免数据竞争（D错误）。并非所有标准算法都有并行版本（B错误），部分算法支持非随机访问（C错误）。

### 设计题参考答案
1. 答案：以下是实现多生产者多消费者线程安全环形队列的代码，基于无锁设计和CAS操作，结合条件变量处理阻塞：
```cpp
#include <iostream>
#include <atomic>
#include <array>
#include <mutex>
#include <condition_variable>

template<typename T, size_t Capacity>
class LockFreeRingBuffer {
public:
    LockFreeRingBuffer() : head_(0), tail_(0) {}

    bool try_enqueue(const T& item) {
        uint64_t current_tail = tail_.load(std::memory_order_relaxed);
        uint32_t current_tail_idx = get_index(current_tail);
        uint32_t next_tail_idx = (current_tail_idx + 1) % Capacity;
        uint64_t current_head = head_.load(std::memory_order_acquire);
        uint32_t current_head_idx = get_index(current_head);

        if (next_tail_idx == current_head_idx) {
            return false; // 队列满
        }

        uint64_t new_tail = make_versioned(next_tail_idx, get_version(current_tail) + 1);
        if (tail_.compare_exchange_strong(current_tail, new_tail,
                                        std::memory_order_acq_rel)) {
            buffer_[current_tail_idx] = item;
            std::atomic_thread_fence(std::memory_order_release);
            not_empty_.notify_one();
            return true;
        }
        return false;
    }

    void enqueue(const T& item) {
        while (true) {
            if (try_enqueue(item)) {
                return;
            }
            std::unique_lock<std::mutex> lock(mutex_);
            not_full_.wait(lock, [this]() {
                uint64_t current_tail = tail_.load(std::memory_order_relaxed);
                uint32_t tail_idx = get_index(current_tail);
                uint32_t head_idx = get_index(head_.load(std::memory_order_relaxed));
                return (tail_idx + 1) % Capacity != head_idx;
            });
        }
    }

    bool try_dequeue(T& item) {
        uint64_t current_head = head_.load(std::memory_order_relaxed);
        uint32_t current_head_idx = get_index(current_head);
        uint64_t current_tail = tail_.load(std::memory_order_acquire);
        uint32_t current_tail_idx = get_index(current_tail);

        if (current_head_idx == current_tail_idx) {
            return false; // 队列空
        }

        uint32_t next_head_idx = (current_head_idx + 1) % Capacity;
        uint64_t new_head = make_versioned(next_head_idx, get_version(current_head) + 1);
        if (head_.compare_exchange_strong(current_head, new_head,
                                         std::memory_order_acq_rel)) {
            std::atomic_thread_fence(std::memory_order_acquire);
            item = buffer_[current_head_idx];
            not_full_.notify_one();
            return true;
        }
        return false;
    }

    void dequeue(T& item) {
        while (true) {
            if (try_dequeue(item)) {
                return;
            }
            std::unique_lock<std::mutex> lock(mutex_);
            not_empty_.wait(lock, [this]() {
                uint32_t head_idx = get_index(head_.load(std::memory_order_relaxed));
                uint32_t tail_idx = get_index(tail_.load(std::memory_order_relaxed));
                return head_idx != tail_idx;
            });
        }
    }

private:
    static constexpr uint32_t get_index(uint64_t v) noexcept {
        return static_cast<uint32_t>(v & 0xFFFFFFFF);
    }

    static constexpr uint32_t get_version(uint64_t v) noexcept {
        return static_cast<uint32_t>(v >> 32);
    }

    static constexpr uint64_t make_versioned(uint32_t index, uint32_t version) noexcept {
        return (static_cast<uint64_t>(version) << 32) | index;
    }

private:
    std::array<T, Capacity> buffer_;
    std::atomic<uint64_t> head_; // 低32位: index, 高32位: version
    std::atomic<uint64_t> tail_;
    std::mutex mutex_;
    std::condition_variable not_full_;
    std::condition_variable not_empty_;
};

int main() {
    LockFreeRingBuffer<int, 1024> queue;

    // 生产者线程
    std::thread producer([&]() {
        for (int i = 0; i < 1000; ++i) {
            queue.enqueue(i);
            std::this_thread::sleep_for(std::chrono::milliseconds(10));
        }
    });

    // 消费者线程
    std::thread consumer([&]() {
        int val;
        for (int i = 0; i < 1000; ++i) {
            queue.dequeue(val);
            std::cout << "Dequeued: " << val << std::endl;
        }
    });

    producer.join();
    consumer.join();
    return 0;
}
```
2. 以下是一个实现多核原子计数器并验证不同内存序可见性的C++代码示例。代码包含两种内存序的对比测试，并演示顺序一致性（memory_order_seq_cst）和松散内存序（memory_order_relaxed）的区别：
```cpp
#include <atomic>
#include <iostream>
#include <thread>
#include <vector>

// 原子计数器模板类（允许指定内存序）
template <typename T, std::memory_order Order>
class AtomicCounter {
public:
    void fetch_add(T value) noexcept {
        counter_.fetch_add(value, Order);
    }

    T load() const noexcept {
        return counter_.load(Order);
    }

private:
    std::atomic<T> counter_{0};
};

// 验证可见性的测试函数
template <typename Counter>
void test_counter_visibility(const char* name, int thread_num, int iterations) {
    Counter counter;
    std::vector<std::thread> threads;

    // 启动多个线程执行累加操作
    for (int i = 0; i < thread_num; ++i) {
        threads.emplace_back([&counter, iterations]() {
            for (int j = 0; j < iterations; ++j) {
                counter.fetch_add(1);
            }
        });
    }

    // 等待所有线程完成
    for (auto& t : threads) {
        t.join();
    }

    // 验证结果是否正确
    const int expected = thread_num * iterations;
    const int actual = counter.load();
    std::cout << "[" << name << "] Expected: " << expected 
              << ", Actual: " << actual 
              << " (" << (expected == actual ? "PASS" : "FAIL") << ")\n";
}

int main() {
    constexpr int kThreads = 4;    // 线程数量
    constexpr int kIterations = 100000; // 每个线程的累加次数

    // 测试顺序一致性模型
    test_counter_visibility<
        AtomicCounter<int, std::memory_order_seq_cst>
    >("SEQ_CST", kThreads, kIterations);

    // 测试松散内存序模型
    test_counter_visibility<
        AtomicCounter<int, std::memory_order_relaxed>
    >("RELAXED", kThreads, kIterations);

    return 0;
}
```
3. 以下是一个使用C++标准库promise/future实现异步处理流水线的完整实现，包含异常传播和优雅终止机制：
```cpp
#include <iostream>
#include <future>
#include <thread>
#include <vector>
#include <stdexcept>
#include <fstream>

// 数据读取阶段
std::future<std::vector<uint8_t>> data_reader() {
    auto promise = std::make_shared<std::promise<std::vector<uint8_t>>>();
    
    std::future<std::vector<uint8_t>> future = promise->get_future();
    
    std::thread([promise]() {
        try {
            // 模拟数据读取（实际可从文件/网络获取）
            std::vector<uint8_t> raw_data = {'H', 'e', 'l', 'l', 'o'};
            std::this_thread::sleep_for(std::chrono::milliseconds(100));
            promise->set_value(raw_data); // 传递数据
        } catch (...) {
            promise->set_exception(std::current_exception());
        }
    }).detach();
    
    return future;
}

// 预处理阶段
std::future<std::vector<uint8_t>> data_preprocessor(std::future<std::vector<uint8_t>>&& input) {
    auto promise = std::make_shared<std::promise<std::vector<uint8_t>>>();
    
    std::future<std::vector<uint8_t>> future = promise->get_future();
    
    std::thread([input = std::move(input), promise]() mutable {
        try {
            auto data = input.get(); // 等待上游数据
            // 模拟预处理（添加头信息）
            data.insert(data.begin(), 0x01); 
            data.push_back(0x02);
            promise->set_value(data);
        } catch (...) {
            promise->set_exception(std::current_exception());
        }
    }).detach();
    
    return future;
}

// 加密阶段（带异常模拟）
std::future<std::vector<uint8_t>> data_encryptor(std::future<std::vector<uint8_t>>&& input) {
    auto promise = std::make_shared<std::promise<std::vector<uint8_t>>>();
    
    std::future<std::vector<uint8_t>> future = promise->get_future();
    
    std::thread([input = std::move(input), promise]() mutable {
        try {
            auto data = input.get();
            // 模拟加密失败
            if (data.size() > 10) {
                throw std::runtime_error("Encryption failed: Data too large");
            }
            // 模拟加密处理（异或简单加密）
            for (auto& b : data) { b ^= 0x55; }
            promise->set_value(data);
        } catch (...) {
            promise->set_exception(std::current_exception());
        }
    }).detach();
    
    return future;
}

// 文件写入阶段
void file_writer(std::future<std::vector<uint8_t>>&& input) {
    std::thread([input = std::move(input)]() mutable {
        try {
            auto data = input.get(); // 等待加密数据
            std::ofstream file("output.bin", std::ios::binary);
            if (!file) throw std::runtime_error("Cannot open file");
            
            file.write(reinterpret_cast<char*>(data.data()), data.size());
            std::cout << "File written successfully\n";
        } catch (const std::exception& e) {
            std::cerr << "Pipeline terminated: " << e.what() << std::endl;
        }
    }).detach();
}

// 流水线控制器
void run_pipeline() {
    try {
        // 构建流水线
        file_writer(
            data_encryptor(
                data_preprocessor(
                    data_reader()
                )
            )
        );
    } catch (...) {
        std::cerr << "Pipeline initialization failed" << std::endl;
    }
}

int main() {
    run_pipeline();
    
    // 保持主线程运行（实际应用可替换为事件循环）
    std::this_thread::sleep_for(std::chrono::seconds(1));
    return 0;
}
```
4. 以下是一个基于C++20标准（使用std::jthread和std::stop_token）实现的可中断线程池的完整代码，包含任务取消和队列清理功能：
```cpp
  #include <iostream>
#include <vector>
#include <queue>
#include <functional>
#include <mutex>
#include <condition_variable>
#include <future>
#include <stop_token>
#include <memory>
#include <atomic>

class InterruptibleThreadPool {
public:
    explicit InterruptibleThreadPool(size_t num_threads = std::thread::hardware_concurrency())
        : stop_source_(std::make_shared<std::stop_source>()) 
    {
        workers_.reserve(num_threads);
        for (size_t i = 0; i < num_threads; ++i) {
            workers_.emplace_back([this](std::stop_token st) {
                worker_thread(st);
            });
        }
    }

    ~InterruptibleThreadPool() {
        stop_source_->request_stop();
        {
            std::unique_lock lock(queue_mutex_);
            task_queue_ = std::priority_queue<Task>(); // 清空队列
        }
        cv_.notify_all();
    }

    template<typename F, typename... Args>
    auto submit(F&& f, Args&&... args) -> std::future<std::invoke_result_t<F, Args..., std::stop_token>> {
        using return_type = std::invoke_result_t<F, Args..., std::stop_token>;
        
        auto task = std::make_shared<std::packaged_task<return_type()>>(
            [func = std::forward<F>(f), ...args = std::forward<Args>(args), st = stop_source_->get_token()]() {
                return func(args..., st); // 传递stop_token给任务
            }
        );

        std::future<return_type> res = task->get_future();
        {
            std::unique_lock lock(queue_mutex_);
            task_queue_.emplace(Task{
                .id = ++task_id_,
                .task = [task]() { (*task)(); },
                .stop_token = stop_source_->get_token()
            });
        }
        cv_.notify_one();
        return res;
    }

    void cancel(uint64_t task_id) {
        std::unique_lock lock(queue_mutex_);
        std::priority_queue<Task> new_queue;
        
        while (!task_queue_.empty()) {
            auto task = task_queue_.top();
            if (task.id != task_id) {
                new_queue.push(std::move(task));
            }
            task_queue_.pop();
        }
        task_queue_ = std::move(new_queue);
    }

private:
    struct Task {
        uint64_t id;
        std::function<void()> task;
        std::stop_token stop_token;
        
        // 优先处理新任务（可根据需要调整策略）
        bool operator<(const Task& rhs) const { return id > rhs.id; }
    };

    void worker_thread(std::stop_token st) {
        while (!st.stop_requested()) {
            std::unique_lock lock(queue_mutex_);
            cv_.wait(lock, [this, &st] {
                return !task_queue_.empty() || st.stop_requested();
            });

            if (st.stop_requested()) break;

            if (!task_queue_.empty()) {
                auto current_task = std::move(const_cast<Task&>(task_queue_.top()));
                task_queue_.pop();
                lock.unlock();

                // 检查任务是否已被取消
                if (!current_task.stop_token.stop_requested()) {
                    current_task.task();
                }
            }
        }
    }

    std::priority_queue<Task> task_queue_;
    std::mutex queue_mutex_;
    std::condition_variable_any cv_;
    std::vector<std::jthread> workers_;
    std::shared_ptr<std::stop_source> stop_source_;
    std::atomic<uint64_t> task_id_{0};
};

// 示例任务（支持中断检查）
void example_task(int duration_ms, std::stop_token st) {
    for (int i = 0; i < duration_ms; ++i) {
        if (st.stop_requested()) {
            std::cout << "任务被中断\n";
            return;
        }
        std::this_thread::sleep_for(std::chrono::milliseconds(1));
    }
    std::cout << "任务完成\n";
}

int main() {
    InterruptibleThreadPool pool(2);

    // 提交任务并获取ID
    auto fut1 = pool.submit(example_task, 1000);
    auto fut2 = pool.submit(example_task, 2000);
    
    // 允许用户取消特定任务（示例取消第二个任务）
    std::this_thread::sleep_for(std::chrono::milliseconds(500));
    pool.cancel(2); // 假设第二个任务的ID是2
    
    // 等待剩余任务完成
    fut1.get();
    try {
        fut2.get();
    } catch (const std::future_error& e) {
        std::cout << "任务2结果: " << e.what() << "\n";
    }

    return 0;
}
```
5. 以下是一个基于带标记指针的无锁栈实现，完整解决ABA问题，包含与有锁版本的性能对比测试：
```cpp
#include <atomic>
#include <iostream>
#include <thread>
#include <vector>
#include <mutex>
#include <chrono>

// 无锁栈实现（带标记指针解决ABA问题）
template<typename T>
class LockFreeStack {
private:
    struct Node;
    struct alignas(16) TaggedPtr { // 16字节对齐保证原子操作
        Node* ptr;
        uintptr_t tag;
    };

    struct Node {
        T data;
        std::atomic<TaggedPtr> next;
        Node(const T& val) : data(val) {}
    };

    std::atomic<TaggedPtr> head_;
    std::atomic<size_t> hazard_count_{0};
    static constexpr size_t kHazardMax = 100;

public:
    LockFreeStack() {
        head_.store(TaggedPtr{nullptr, 0});
    }

    ~LockFreeStack() {
        TaggedPtr h = head_.load();
        while (Node* node = h.ptr) {
            h = node->next.load();
            delete node;
        }
    }

    void push(const T& val) {
        Node* new_node = new Node(val);
        TaggedPtr old_head = head_.load(std::memory_order_relaxed);
        while (true) {
            new_node->next.store(old_head, std::memory_order_relaxed);
            TaggedPtr new_head{new_node, old_head.tag + 1};
            if (head_.compare_exchange_weak(old_head, new_head,
                                          std::memory_order_release,
                                          std::memory_order_relaxed)) {
                return;
            }
        }
    }

    bool pop(T& val) {
        TaggedPtr old_head = head_.load(std::memory_order_acquire);
        while (true) {
            if (!old_head.ptr) return false;
            
            // 使用Hazard指针保护当前节点
            hazard_count_.fetch_add(1);
            TaggedPtr new_head = old_head.ptr->next.load(std::memory_order_relaxed);
            new_head.tag = old_head.tag + 1;
            
            if (head_.compare_exchange_weak(old_head, new_head,
                                          std::memory_order_acq_rel,
                                          std::memory_order_acquire)) {
                val = old_head.ptr->data;
                reclaim_later(old_head.ptr);
                hazard_count_.fetch_sub(1);
                return true;
            }
            
            hazard_count_.fetch_sub(1);
        }
    }

private:
    thread_local static Node* hazard_list_; // Hazard指针列表

    void reclaim_later(Node* node) {
        static thread_local std::vector<Node*> retire_list;
        retire_list.push_back(node);
        
        if (retire_list.size() >= kHazardMax) {
            reclaim_all();
        }
    }

    void reclaim_all() {
        for (auto it = retire_list.begin(); it != retire_list.end();) {
            if (is_safe(*it)) {
                delete *it;
                it = retire_list.erase(it);
            } else {
                ++it;
            }
        }
    }

    bool is_safe(Node* node) {
        TaggedPtr h = head_.load();
        while (Node* curr = h.ptr) {
            if (curr == node) return false;
            h = curr->next.load();
        }
        return hazard_count_.load() == 0;
    }
};

// 有锁栈实现
template<typename T>
class LockedStack {
    struct Node {
        T data;
        Node* next;
        Node(const T& val) : data(val), next(nullptr) {}
    };

    Node* head_ = nullptr;
    std::mutex mtx_;

public:
    void push(const T& val) {
        Node* new_node = new Node(val);
        std::lock_guard<std::mutex> lock(mtx_);
        new_node->next = head_;
        head_ = new_node;
    }

    bool pop(T& val) {
        std::lock_guard<std::mutex> lock(mtx_);
        if (!head_) return false;
        
        Node* old_head = head_;
        val = old_head->data;
        head_ = old_head->next;
        delete old_head;
        return true;
    }
};

// ABA测试场景
void aba_test() {
    LockFreeStack<int> stack;
    
    // 初始状态：A->B->C
    stack.push(3);
    stack.push(2);
    stack.push(1);

    std::thread t1([&] {
        int val;
        stack.pop(val); // 弹出1
        stack.pop(val); // 弹出2
    });

    std::thread t2([&] {
        int val;
        stack.pop(val); // 弹出1
        stack.push(1);  // 重新插入1（新节点）
    });

    t1.join();
    t2.join();

    // 验证最终状态
    int val;
    while (stack.pop(val)) {
        std::cout << val << " ";
    }
    // 正确输出应为 3（如果ABA问题解决）
}

// 性能测试
template<typename Stack>
void benchmark(const char* name) {
    constexpr int kOps = 1'000'000;
    Stack stack;
    
    auto start = std::chrono::high_resolution_clock::now();
    
    std::thread t1([&] {
        for (int i = 0; i < kOps; ++i) {
            stack.push(i);
        }
    });
    
    std::thread t2([&] {
        for (int i = 0; i < kOps; ++i) {
            int val;
            while (!stack.pop(val));
        }
    });
    
    t1.join();
    t2.join();
    
    auto end = std::chrono::high_resolution_clock::now();
    std::cout << name << " time: "
              << std::chrono::duration_cast<std::chrono::milliseconds>(end - start).count()
              << " ms\n";
}

int main() {
    // ABA问题验证测试
    aba_test();  // 应输出 3
    
    // 性能对比测试
    benchmark<LockFreeStack<int>>("LockFreeStack");
    benchmark<LockedStack<int>>("LockedStack");
    
    return 0;
}
```
6. 以下是一个基于C++标准库实现的工作窃取调度器，使用条件变量和双端队列实现任务调度与负载均衡：
```cpp
#include <deque>
#include <vector>
#include <thread>
#include <mutex>
#include <condition_variable>
#include <atomic>
#include <random>
#include <functional>
#include <future>
#include <chrono>

class WorkStealingScheduler {
public:
    explicit WorkStealingScheduler(size_t num_workers = std::thread::hardware_concurrency())
        : stop_(false) {
        workers_.reserve(num_workers);
        for (size_t i = 0; i < num_workers; ++i) {
            workers_.emplace_back(new Worker(*this, i));
        }
        for (auto& w : workers_) {
            w->start();
        }
    }

    ~WorkStealingScheduler() {
        stop_.store(true, std::memory_order_release);
        for (auto& w : workers_) {
            w->join();
        }
    }

    template<typename F>
    auto submit(F&& f) -> std::future<decltype(f())> {
        using result_type = decltype(f());
        
        // 随机选择初始Worker进行任务提交
        static thread_local std::mt19937 rng(std::random_device{}());
        std::uniform_int_distribution<size_t> dist(0, workers_.size()-1);
        auto& worker = *workers_[dist(rng)];
        
        auto task = std::make_shared<std::packaged_task<result_type()>>(
            std::forward<F>(f)
        );
        std::future<result_type> future = task->get_future();
        
        worker.push_task([task]() { (*task)(); });
        return future;
    }

private:
    class Worker {
    public:
        Worker(WorkStealingScheduler& scheduler, size_t id)
            : scheduler_(scheduler), id_(id) {}
            
        void start() {
            thread_ = std::thread([this] { run(); });
        }

        void join() {
            if (thread_.joinable()) thread_.join();
        }

        void push_task(std::function<void()> task) {
            {
                std::lock_guard lock(mutex_);
                queue_.emplace_front(std::move(task));
            }
            cv_.notify_one();
        }

        bool try_steal(std::function<void()>& task) {
            std::lock_guard lock(mutex_);
            if (queue_.empty()) return false;
            
            task = std::move(queue_.back());
            queue_.pop_back();
            return true;
        }

    private:
        void run() {
            std::function<void()> task;
            while (!scheduler_.stop_.load(std::memory_order_acquire)) {
                if (try_local_task(task) || try_steal_task(task) || wait_for_task()) {
                    execute_task(task);
                }
            }
        }

        bool try_local_task(std::function<void()>& task) {
            std::lock_guard lock(mutex_);
            if (!queue_.empty()) {
                task = std::move(queue_.front());
                queue_.pop_front();
                return true;
            }
            return false;
        }

        bool try_steal_task(std::function<void()>& task) {
            static thread_local std::mt19937 rng(std::random_device{}());
            std::uniform_int_distribution<size_t> dist(0, scheduler_.workers_.size()-1);
            
            for (size_t i = 0; i < scheduler_.workers_.size(); ++i) {
                size_t victim = (id_ + i) % scheduler_.workers_.size();
                if (victim == id_) continue;
                
                if (scheduler_.workers_[victim]->try_steal(task)) {
                    return true;
                }
            }
            return false;
        }

        bool wait_for_task() {
            std::unique_lock lock(mutex_);
            if (queue_.empty()) {
                scheduler_.idle_cv_.wait_for(lock, std::chrono::milliseconds(100),
                    [this] { return !queue_.empty() || scheduler_.stop_.load(); });
            }
            return !queue_.empty();
        }

        void execute_task(std::function<void()>& task) {
            try {
                task();
            } catch (...) {
                // 异常处理逻辑
            }
            task = nullptr;
        }

        WorkStealingScheduler& scheduler_;
        size_t id_;
        std::thread thread_;
        std::deque<std::function<void()>> queue_;
        std::mutex mutex_;
        std::condition_variable cv_;
    };

    std::atomic<bool> stop_;
    std::vector<std::unique_ptr<Worker>> workers_;
    std::condition_variable idle_cv_;
};

// 使用示例
int main() {
    WorkStealingScheduler scheduler(4);
    std::vector<std::future<int>> futures;

    // 提交100个任务
    for (int i = 0; i < 100; ++i) {
        futures.emplace_back(scheduler.submit([i] {
            std::this_thread::sleep_for(std::chrono::milliseconds(10));
            return i * i;
        }));
    }

    // 获取结果
    for (auto& f : futures) {
        std::cout << f.get() << " ";
    }
    return 0;
}
```
7. 以下是一个实现并行快速排序优化的C++代码示例，包含C++17标准并行策略和手动线程池两种实现方式的性能对比，并处理了递归任务调度和小数组优化：
```cpp
#include <algorithm>
#include <execution>
#include <vector>
#include <iostream>
#include <random>
#include <chrono>
#include <thread>
#include <queue>
#include <mutex>
#include <condition_variable>
#include <future>

constexpr size_t SERIAL_THRESHOLD = 1024;

// C++17标准并行快速排序
void std_parallel_quicksort(std::vector<int>::iterator begin, 
                           std::vector<int>::iterator end) {
    if (begin >= end) return;
    
    if (end - begin < SERIAL_THRESHOLD) {
        std::sort(begin, end);
        return;
    }

    auto pivot = *std::next(begin, std::distance(begin, end)/2);
    auto middle = std::partition(std::execution::par, begin, end, 
                               [pivot](int x) { return x < pivot; });
    
    std::future<void> left = std::async(std::launch::async, 
                                      std_parallel_quicksort, begin, middle);
    std_parallel_quicksort(middle, end);
    left.wait();
}

// 手动线程池实现
class ThreadPool {
public:
    explicit ThreadPool(size_t threads = std::thread::hardware_concurrency())
        : stop(false) {
        for (size_t i = 0; i < threads; ++i)
            workers.emplace_back([this] { worker_loop(); });
    }

    template<class F>
    auto enqueue(F&& f) -> std::future<decltype(f())> {
        using return_type = decltype(f());
        
        auto task = std::make_shared<std::packaged_task<return_type()>>(
            std::forward<F>(f)
        );
        
        std::future<return_type> res = task->get_future();
        {
            std::unique_lock lock(queue_mutex);
            tasks.emplace([task]() { (*task)(); });
        }
        cv.notify_one();
        return res;
    }

    ~ThreadPool() {
        {
            std::unique_lock lock(queue_mutex);
            stop = true;
        }
        cv.notify_all();
        for (std::thread& worker : workers)
            worker.join();
    }

private:
    void worker_loop() {
        while (true) {
            std::function<void()> task;
            {
                std::unique_lock lock(queue_mutex);
                cv.wait(lock, [this] { return stop || !tasks.empty(); });
                
                if (stop && tasks.empty()) return;
                
                task = std::move(tasks.front());
                tasks.pop();
            }
            task();
        }
    }

    std::vector<std::thread> workers;
    std::queue<std::function<void()>> tasks;
    std::mutex queue_mutex;
    std::condition_variable cv;
    bool stop;
};

void pool_parallel_quicksort(ThreadPool& pool, 
                            std::vector<int>::iterator begin,
                            std::vector<int>::iterator end) {
    if (begin >= end) return;
    
    if (end - begin < SERIAL_THRESHOLD) {
        std::sort(begin, end);
        return;
    }

    auto pivot = *std::next(begin, std::distance(begin, end)/2);
    auto middle = std::partition(std::execution::par_unseq, begin, end,
                                [pivot](int x) { return x < pivot; });
    
    auto left = pool.enqueue([&pool, begin, middle] { 
        pool_parallel_quicksort(pool, begin, middle); 
    });
    
    pool_parallel_quicksort(pool, middle, end);
    left.wait();
}

// 性能测试函数
template<typename F>
void benchmark(const std::string& name, F&& sort_func, 
              std::vector<int>& data) {
    auto start = std::chrono::high_resolution_clock::now();
    sort_func();
    auto end = std::chrono::high_resolution_clock::now();
    
    std::cout << name << " time: "
              << std::chrono::duration_cast<std::chrono::milliseconds>(end - start).count()
              << " ms\n";
    
    // 验证排序正确性
    if (!std::is_sorted(data.begin(), data.end())) {
        std::cerr << "Sort failed!\n";
    }
}

int main() {
    // 生成测试数据
    constexpr size_t N = 10'000'000;
    std::vector<int> data(N);
    std::mt19937 rng(std::random_device{}());
    std::generate(data.begin(), data.end(), [&rng]() { return rng() % N; });
    auto data1 = data; // 拷贝数据用于不同测试

    // 测试不同实现
    ThreadPool pool;
    
    benchmark("STD Parallel", [&] { 
        std_parallel_quicksort(data.begin(), data.end()); 
    }, data);
    
    benchmark("Thread Pool", [&] {
        pool_parallel_quicksort(pool, data1.begin(), data1.end());
    }, data1);
    
    benchmark("Baseline (STD Sort)", [&] { 
        std::sort(data.begin(), data.end()); 
    }, data);

    return 0;
}

8. 以下是一个基于C++17实现的细粒度锁哈希表，包含动态扩缩容和性能对比测试的实现：
```cpp
#include <vector>
#include <list>
#include <mutex>
#include <atomic>
#include <thread>
#include <iostream>
#include <chrono>
#include <functional>
#include <random>

template<typename Key, typename Value, size_t INITIAL_SIZE = 64>
class ConcurrentHashTable {
private:
    struct Bucket {
        std::mutex mtx;
        std::list<std::pair<Key, Value>> data;
    };

    // 当前活跃表
    std::vector<std::unique_ptr<Bucket>> current_table_;
    std::atomic<size_t> current_capacity_;
    std::atomic<size_t> item_count_{0};
    
    // 扩容相关
    std::vector<std::unique_ptr<Bucket>> new_table_;
    std::atomic<bool> is_rehashing_{false};
    std::atomic<size_t> rehash_index_{0};
    std::mutex rehash_mtx_;
    const float LOAD_FACTOR = 0.75f;

public:
    ConcurrentHashTable() : current_capacity_(INITIAL_SIZE) {
        initialize_table(current_table_, INITIAL_SIZE);
    }

    void insert(const Key& key, const Value& value) {
        check_rehash();

        auto& tables = get_active_tables();
        size_t hash = std::hash<Key>{}(key);
        
        // 插入到所有活跃表中
        for (auto& table : tables) {
            size_t idx = hash % table->capacity;
            auto& bucket = table->buckets[idx];
            std::lock_guard<std::mutex> lock(bucket.mtx);
            
            for (auto& pair : bucket.data) {
                if (pair.first == key) {
                    pair.second = value;
                    return;
                }
            }
            bucket.data.emplace_back(key, value);
            item_count_.fetch_add(1, std::memory_order_relaxed);
        }
    }

    bool find(const Key& key, Value& out) {
        auto tables = get_active_tables();
        size_t hash = std::hash<Key>{}(key);

        for (auto& table : tables) {
            size_t idx = hash % table->capacity;
            auto& bucket = table->buckets[idx];
            std::lock_guard<std::mutex> lock(bucket.mtx);
            
            for (auto& pair : bucket.data) {
                if (pair.first == key) {
                    out = pair.second;
                    return true;
                }
            }
            
            // 如果在旧表中找到且正在rehash，需要检查新表
            if (!is_rehashing_.load()) break;
        }
        return false;
    }

    void erase(const Key& key) {
        auto tables = get_active_tables();
        size_t hash = std::hash<Key>{}(key);

        for (auto& table : tables) {
            size_t idx = hash % table->capacity;
            auto& bucket = table->buckets[idx];
            std::lock_guard<std::mutex> lock(bucket.mtx);
            
            auto it = bucket.data.begin();
            while (it != bucket.data.end()) {
                if (it->first == key) {
                    bucket.data.erase(it);
                    item_count_.fetch_sub(1, std::memory_order_relaxed);
                    return;
                }
                ++it;
            }
            
            if (!is_rehashing_.load()) break;
        }
    }

private:
    struct Table {
        size_t capacity;
        std::vector<Bucket> buckets;
    };

    std::shared_ptr<Table> main_table_;
    std::shared_ptr<Table> old_table_;
    
    void initialize_table(std::shared_ptr<Table>& table, size_t size) {
        table = std::make_shared<Table>();
        table->capacity = size;
        table->buckets.resize(size);
    }

    void check_rehash() {
        if (need_rehash() && !is_rehashing_.exchange(true)) {
            std::thread([this] { progressive_rehash(); }).detach();
        }
    }

    bool need_rehash() const {
        return item_count_.load() > main_table_->capacity * LOAD_FACTOR;
    }

    void progressive_rehash() {
        size_t batch_size = main_table_->capacity / 16; // 每次迁移1/16的桶
        
        for (size_t i = 0; i < main_table_->capacity; i += batch_size) {
            migrate_buckets(i, std::min(i + batch_size, main_table_->capacity));
            
            // 更新当前表指针
            std::lock_guard<std::mutex> lock(rehash_mtx_);
            old_table_ = main_table_;
            initialize_table(main_table_, old_table_->capacity * 2);
        }
        
        is_rehashing_.store(false);
    }

    void migrate_buckets(size_t start, size_t end) {
        for (size_t i = start; i < end; ++i) {
            auto& old_bucket = old_table_->buckets[i];
            std::lock_guard<std::mutex> lock(old_bucket.mtx);
            
            for (auto& pair : old_bucket.data) {
                size_t new_hash = std::hash<Key>{}(pair.first);
                size_t new_idx = new_hash % main_table_->capacity;
                auto& new_bucket = main_table_->buckets[new_idx];
                std::lock_guard<std::mutex> new_lock(new_bucket.mtx);
                new_bucket.data.push_back(pair);
            }
        }
    }

    std::vector<std::shared_ptr<Table>> get_active_tables() {
        std::vector<std::shared_ptr<Table>> tables;
        tables.push_back(main_table_);
        if (is_rehashing_.load()) {
            tables.push_back(old_table_);
        }
        return tables;
    }
};

// 基准测试函数
template<typename HashTable>
void benchmark(const char* name) {
    HashTable table;
    constexpr int TOTAL_OPS = 1000000;
    std::atomic<int> counter{0};
    
    auto start = std::chrono::high_resolution_clock::now();
    
    std::vector<std::thread> threads;
    for (int i = 0; i < 8; ++i) {
        threads.emplace_back([&] {
            std::random_device rd;
            std::mt19937 gen(rd());
            std::uniform_int_distribution<> dis(0, 100000);
            
            for (int j = 0; j < TOTAL_OPS/8; ++j) {
                int key = dis(gen);
                table.insert(key, key*2);
                int val;
                table.find(key, val);
                table.erase(key);
                counter.fetch_add(1, std::memory_order_relaxed);
            }
        });
    }
    
    for (auto& t : threads) t.join();
    
    auto end = std::chrono::high_resolution_clock::now();
    std::cout << name << " throughput: " 
              << TOTAL_OPS / std::chrono::duration<double>(end - start).count() 
              << " ops/s\n";
}

int main() {
    // 对比测试
    benchmark<ConcurrentHashTable<int, int>>("Fine-grained Lock");
    
    // 全局锁版本对比（仅需修改锁机制）
    // benchmark<GlobalLockHashTable>("Global Lock");
    
    return 0;
}
```
9. 步骤1：必然发生死锁的代码实现
```cpp
#include <mutex>
#include <thread>
#include <chrono>

std::mutex mutex1;
std::mutex mutex2;

void thread_a() {
    std::lock_guard<std::mutex> lock1(mutex1);  // 先锁mutex1
    std::this_thread::sleep_for(std::chrono::milliseconds(100));
    std::lock_guard<std::mutex> lock2(mutex2);   // 再锁mutex2
    std::cout << "Thread A acquired both locks\n";
}

void thread_b() {
    std::lock_guard<std::mutex> lock2(mutex2);  // 先锁mutex2
    std::this_thread::sleep_for(std::chrono::milliseconds(100));
    std::lock_guard<std::mutex> lock1(mutex1);  // 再锁mutex1
    std::cout << "Thread B acquired both locks\n";
}

int main() {
    std::thread t1(thread_a);
    std::thread t2(thread_b);
    t1.join();
    t2.join();
    return 0;
}
```
死锁现象：
- 线程A锁定mutex1后尝试获取mutex2
- 线程B锁定mutex2后尝试获取mutex1
- 两者互相等待形成死锁

步骤2：使用C++17的scoped_lock修复死锁
```cpp
#include <mutex>
#include <thread>
#include <chrono>

std::mutex mutex1;
std::mutex mutex2;

void thread_a() {
    std::scoped_lock lock(mutex1, mutex2);  // 原子化锁定
    std::cout << "Thread A acquired both locks\n";
}

void thread_b() {
    std::scoped_lock lock(mutex1, mutex2);  // 顺序自动调整
    std::cout << "Thread B acquired both locks\n";
}

int main() {
    std::thread t1(thread_a);
    std::thread t2(thread_b);
    t1.join();
    t2.join();
    return 0;
}
```
以下是检测并修复死锁场景的完整代码示例，包含原始死锁实现、修复方案及工具验证方法：

步骤1：必然发生死锁的代码实现
```cpp
#include <mutex>
#include <thread>
#include <chrono>

std::mutex mutex1;
std::mutex mutex2;

void thread_a() {
    std::lock_guard<std::mutex> lock1(mutex1);  // 先锁mutex1
    std::this_thread::sleep_for(std::chrono::milliseconds(100));
    std::lock_guard<std::mutex> lock2(mutex2);   // 再锁mutex2
    std::cout << "Thread A acquired both locks\n";
}

void thread_b() {
    std::lock_guard<std::mutex> lock2(mutex2);  // 先锁mutex2
    std::this_thread::sleep_for(std::chrono::milliseconds(100));
    std::lock_guard<std::mutex> lock1(mutex1);  // 再锁mutex1
    std::cout << "Thread B acquired both locks\n";
}

int main() {
    std::thread t1(thread_a);
    std::thread t2(thread_b);
    t1.join();
    t2.join();
    return 0;
}
```
死锁现象：
线程A锁定mutex1后尝试获取mutex2
线程B锁定mutex2后尝试获取mutex1
两者互相等待形成死锁
步骤2：使用C++17的scoped_lock修复死锁
```cpp
#include <mutex>
#include <thread>
#include <chrono>

std::mutex mutex1;
std::mutex mutex2;

void thread_a() {
    std::scoped_lock lock(mutex1, mutex2);  // 原子化锁定
    std::cout << "Thread A acquired both locks\n";
}

void thread_b() {
    std::scoped_lock lock(mutex1, mutex2);  // 顺序自动调整
    std::cout << "Thread B acquired both locks\n";
}

int main() {
    std::thread t1(thread_a);
    std::thread t2(thread_b);
    t1.join();
    t2.join();
    return 0;
}
```

修复原理：
1. std::scoped_lock使用C++标准库的死锁避免算法
2. 内部实现自动确定互斥量的锁定顺序（如地址排序）
3. 保证多个互斥量的原子化锁定

步骤3：使用ThreadSanitizer验证
编译命令（Clang++）：
```bash
# 原始死锁版本
clang++ -std=c++17 -g -fsanitize=thread deadlock.cpp -o deadlock

# 修复后版本
clang++ -std=c++17 -g -fsanitize=thread fixed.cpp -o fixed
```
检测结果对比：
死锁版本输出：
```
Thread A acquired both locks
```
修复后版本输出：
```
Thread A acquired both locks
Thread B acquired both locks
```
步骤4：分层锁策略实现（替代方案）
```cpp
class HierarchicalLock {
public:
    explicit HierarchicalLock(uint64_t level) : current_level(level) {}
    
    void lock() {
        if (current_level <= last_level) {
            throw std::logic_error("Lock hierarchy violated");
        }
        mtx.lock();
        last_level = current_level;
    }
    
    void unlock() {
        last_level = 0;
        mtx.unlock();
    }

private:
    static thread_local uint64_t last_level;
    uint64_t current_level;
    std::mutex mtx;
};

thread_local uint64_t HierarchicalLock::last_level = 0;

// 使用示例
HierarchicalLock high(1000);
HierarchicalLock low(500);

void safe_thread() {
    std::lock_guard<HierarchicalLock> lock1(high);
    std::lock_guard<HierarchicalLock> lock2(low); // 层级检查失败抛出异常
}
```
分层锁优势：
1. 强制定义锁的获取顺序
2. 运行时检查层级规则
3. 避免潜在的顺序错误
10. 以下是一个基于原子操作的无锁内存池实现，包含ABA问题防御和性能优化：
```cpp
#include <atomic>
#include <memory>
#include <iostream>
#include <thread>
#include <vector>
#include <cstdint>
#include <cstdlib>

// 缓存行大小对齐（避免伪共享）
constexpr size_t CACHE_LINE_SIZE = 64;

// 带标签指针结构（128位原子操作）
struct alignas(CACHE_LINE_SIZE) TaggedPtr {
    void* ptr;
    uintptr_t tag;
};

// 内存块结构
struct alignas(CACHE_LINE_SIZE) MemoryBlock {
    std::atomic<TaggedPtr> next;  // 用于空闲链表
    char data[];                   // 用户数据区域
};

class LockFreeMemoryPool {
public:
    LockFreeMemoryPool(size_t block_size, size_t num_blocks)
        : block_size_(block_size) {
        initialize_pool(num_blocks);
    }

    ~LockFreeMemoryPool() {
        std::free(pool_);
    }

    void* allocate() {
        TaggedPtr old_head = head_.load(std::memory_order_acquire);
        
        while (true) {
            if (!old_head.ptr) return nullptr;  // 内存耗尽
            
            MemoryBlock* current = static_cast<MemoryBlock*>(old_head.ptr);
            TaggedPtr new_head = current->next.load(std::memory_order_relaxed);
            
            // 使用双宽度CAS更新头指针
            if (head_.compare_exchange_weak(old_head, new_head,
                                          std::memory_order_acq_rel,
                                          std::memory_order_acquire)) {
                return current->data;  // 返回用户数据区地址
            }
        }
    }

    void deallocate(void* ptr) {
        MemoryBlock* block = get_block_from_data(ptr);
        
        TaggedPtr old_head = head_.load(std::memory_order_acquire);
        while (true) {
            // 设置回收块的next指针
            TaggedPtr new_head{block, old_head.tag + 1};
            block->next.store(old_head, std::memory_order_relaxed);
            
            if (head_.compare_exchange_weak(old_head, new_head,
                                          std::memory_order_acq_rel,
                                          std::memory_order_acquire)) {
                return;
            }
        }
    }

private:
    void initialize_pool(size_t num_blocks) {
        // 计算总内存大小（包含元数据）
        size_t total_size = num_blocks * (sizeof(MemoryBlock) + block_size_);
        pool_ = static_cast<MemoryBlock*>(std::aligned_alloc(CACHE_LINE_SIZE, total_size));
        
        // 构建初始空闲链表
        TaggedPtr prev{nullptr, 0};
        char* raw = reinterpret_cast<char*>(pool_);
        
        for (size_t i = 0; i < num_blocks; ++i) {
            MemoryBlock* current = reinterpret_cast<MemoryBlock*>(
                raw + i * (sizeof(MemoryBlock) + block_size_));
            
            current->next.store(prev, std::memory_order_relaxed);
            prev.ptr = current;
            prev.tag = 0;
        }
        
        head_.store(prev, std::memory_order_release);
    }

    MemoryBlock* get_block_from_data(void* data) const {
        return reinterpret_cast<MemoryBlock*>(
            static_cast<char*>(data) - offsetof(MemoryBlock, data));
    }

    alignas(CACHE_LINE_SIZE) std::atomic<TaggedPtr> head_;
    MemoryBlock* pool_;
    size_t block_size_;
};

// 性能测试
void benchmark() {
    constexpr size_t BLOCK_SIZE = 64;
    constexpr size_t NUM_BLOCKS = 1'000'000;
    constexpr int THREADS = 8;
    constexpr int OPS_PER_THREAD = 100'000;
    
    LockFreeMemoryPool pool(BLOCK_SIZE, NUM_BLOCKS);
    std::vector<std::thread> threads;
    std::atomic<int> counter{0};
    
    auto start = std::chrono::high_resolution_clock::now();
    
    for (int i = 0; i < THREADS; ++i) {
        threads.emplace_back([&] {
            std::vector<void*> ptrs;
            ptrs.reserve(OPS_PER_THREAD);
            
            // 分配测试
            for (int j = 0; j < OPS_PER_THREAD; ++j) {
                if (void* p = pool.allocate()) {
                    ptrs.push_back(p);
                    counter.fetch_add(1, std::memory_order_relaxed);
                }
            }
            
            // 释放测试
            for (void* p : ptrs) {
                pool.deallocate(p);
                counter.fetch_sub(1, std::memory_order_relaxed);
            }
        });
    }
    
    for (auto& t : threads) t.join();
    
    auto end = std::chrono::high_resolution_clock::now();
    std::cout << "Throughput: " 
              << (THREADS * OPS_PER_THREAD * 2) / 
                  std::chrono::duration<double>(end - start).count()
              << " ops/sec\n";
    std::cout << "Final counter: " << counter.load() << " (should be 0)\n";
}

int main() {
    benchmark();
    return 0;
}
```